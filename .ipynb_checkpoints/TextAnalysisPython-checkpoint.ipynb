{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=5 face='arial black'> Text Analysis in Python </font></p>\n",
    "\n",
    "<p>Python is a powerful programming language that's especially suited to text analysis. In this workshop, we will cover some of the most state to the art packages in python for processing text.</p>\n",
    "\n",
    "<p>Compared to the rest of python, these packages are much less developed. They require a higher tolerance for non-intuitive interface and experimental, incompletely or imperfect features. However, if you stick with it, you can do many very cool things.</p>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Quick Discussion of Cleaning </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_file = open('alice_in_wonderland.txt','r')\n",
    "alice = alice_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(alice[:335])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_paragraph=alice[:335]\n",
    "print(raw_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph = raw_paragraph.lower()\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(paragraph.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation_list = list(string.punctuation)+['â€™']\n",
    "print(punctuation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empty_list = ['']*len(punctuation_list)\n",
    "print(empty_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipped_list = list(zip(punctuation_list,empty_list))\n",
    "print(zipped_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "substitution_dictionary=dict(zipped_list)\n",
    "print(substitution_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translation=str.maketrans(dict(zipped_list))\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraph.translate(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_punctuation_cleaner(text):\n",
    "    punctuation_list = list(string.punctuation)\n",
    "    empty_list = ['']*len(punctuation_list)\n",
    "    zipped_list = zip(punctuation_list,empty_list)\n",
    "    translation=str.maketrans(dict(zipped_list))\n",
    "    return text.translate(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_punctuation_text = simple_punctuation_cleaner(paragraph)\n",
    "print(no_punctuation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(no_punctuation_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "print(word_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "tokenized_text = tokenizer(paragraph)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "print(sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def has_no_numbers(inputString):\n",
    "     return not any(char.isdigit() for char in inputString)\n",
    "\n",
    "print( has_no_numbers('aa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(filter(has_no_numbers, ['cat','k33p','dog','mouse','1221']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_numbers_from_word_list(word_list):\n",
    "    return list(filter(has_no_numbers, word_list))\n",
    "\n",
    "filter_numbers_from_word_list(['cat','k33p','dog','mouse','1221'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "porter_stemmer.stem('president')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Preparing Our Data </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "shakespeare = pd.read_csv('will_play_text.data',delimiter=';',index_col=0,names=['play','act','index','speaker','dialogue'])\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakespeare = shakespeare[shakespeare['speaker'].notnull()]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shakespeare = shakespeare[['speaker','dialogue']]\n",
    "shakespeare.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speech = shakespeare.groupby('speaker').apply(lambda x: \" \".join(x['dialogue']))\n",
    "speech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "characters = pd.DataFrame()\n",
    "characters['dialogue']=speech\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = characters['dialogue'].tolist()\n",
    "print(corpus[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_list = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#solution 1\n",
    "#from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "#stopword_list = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#solution 2\n",
    "#import pickle\n",
    "#stopword_list = pickle.load(open('stopwords.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Cleaning Our Data </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_tokenize(raw_text,custom_stopwords=None):\n",
    "    if custom_stopwords == None: custom_stopwords=[] \n",
    "    \n",
    "    #tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+').tokenize\n",
    "    words = tokenizer(raw_text)\n",
    "    \n",
    "    #filter\n",
    "    words = [word for word in words if word not in set(custom_stopwords+stopword_list)]\n",
    "    \n",
    "    #filter digits\n",
    "    words = filter_numbers_from_word_list(words)\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_corpus = list(map(clean_and_tokenize, corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip.main(['install', 'gensim'])\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\" \".join(cleaned_corpus[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> Topic Analysis with Gensim</font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(cleaned_corpus)\n",
    "vecs = [dictionary.doc2bow(document) for document in cleaned_corpus]\n",
    "\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(vecs)\n",
    "tfidf_vecs = tfidf[vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "lda = LdaModel(corpus=tfidf_vecs,id2word=dictionary,num_topics=2,update_every=0,passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=4 face='arial black'> A Quick Tour of Advanced Text Manipulation </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> spellchecking </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'pyenchant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "eng = enchant.Dict(\"en_US\")\n",
    "eng.check(\"Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> TextBlob </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install TextBlob\n",
    "import pip\n",
    "pip.main(['install', 'TextBlob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "raw_paragraph = \\\n",
    "\"I have a cat. I think she is okay. She thinks milk is awesome. Usually, the milk is cold. I hate cold milk.\"\n",
    "\n",
    "blob = TextBlob(raw_paragraph)\n",
    "\n",
    "for sentence in blob.sentences:\n",
    "    print(\"original:\",sentence)\n",
    "    print(\"grammar:\", sentence.tags)\n",
    "    print(\"polarity:\",sentence.sentiment.polarity)\n",
    "    print(\"subjective:\",sentence.sentiment.subjectivity)\n",
    "    print(sentence.words)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "npr = urlopen('http://www.npr.org/')\n",
    "npr_html = npr.read()\n",
    "npr_html[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> webpages </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pip.main(['install', 'bs4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://stackoverflow.com/questions/1936466/beautifulsoup-grab-visible-webpage-text\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def remove_(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(element)):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_html(html):\n",
    "    soup = BeautifulSoup(npr_html, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(visible, texts)\n",
    "    text = \" \".join(visible_texts)\n",
    "    return(text)\n",
    "\n",
    "cleaned_html = clean_html(npr_html)\n",
    "print(cleaned_html[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> n-grams </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams, ngrams\n",
    "tokens = word_tokenize('I had a cat.')\n",
    "bgs = bigrams(tokens)\n",
    "print(list(bgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(ngrams(tokens,n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> grammar </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import RegexpTokenizer\n",
    "\n",
    "tokenize = RegexpTokenizer(r'\\w+').tokenize\n",
    "\n",
    "tokens = tokenize('I have a cat. His name was Bob. Bob had a ball.')\n",
    "tagged_sentence = pos_tag(tokens)\n",
    "tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = list(zip(*tagged_sentence))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,grammar = zip(*tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#505050 size=3 face='arial black'>\n",
    "<p><font color=#13577F size=3 face='arial black'> inflect </font></p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'inflect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#https://pypi.python.org/pypi/inflect\n",
    "import inflect\n",
    "english = inflect.engine()\n",
    "english.plural('wolf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english.singular_noun('oxen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english.number_to_words(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english.ordinal(106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "english.join([\"apple\", \"banana\", \"carrot\"])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
